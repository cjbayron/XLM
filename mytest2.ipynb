{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from src.model.transformer import TransformerModel\n",
    "from src.model import check_model_params, build_model\n",
    "import src.data.loader as loader\n",
    "from src.trainer import EncDecTrainer\n",
    "from src.evaluation.evaluator import EncDecEvaluator, convert_to_text\n",
    "\n",
    "import myutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'mlm_enfr_1024.pth'\n",
    "SRC_LANG = 'en' # distinction between SRC/TGT not really necessary?\n",
    "TGT_LANG = 'fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = myutils.get_parser()\n",
    "params = parser.parse_args([\n",
    "    '--dump_path', './dumped/',\n",
    "    '--reload_model', '{0},{0}'.format(MODEL_PATH),\n",
    "    \n",
    "    ## data\n",
    "    '--data_path', './data/processed/en-fr/',\n",
    "    '--lgs', '{0}-{1}'.format(SRC_LANG, TGT_LANG),\n",
    "    '--ae_steps', '{0},{1}'.format(SRC_LANG, TGT_LANG),\n",
    "    '--bt_steps', '{0}-{1}-{0},{1}-{0}-{1}'.format(SRC_LANG, TGT_LANG),\n",
    "    '--word_shuffle', '3',\n",
    "    '--word_dropout', '0.1',\n",
    "    '--word_blank', '0.1',\n",
    "    '--lambda_ae', '0:1,100000:0.1,300000:0',\n",
    "    \n",
    "    ## transformer\n",
    "    '--encoder_only', 'false',\n",
    "    '--emb_dim', '1024',                                                \n",
    "    '--n_layers', '6',                                                  \n",
    "    '--n_heads', '8',                                                 \n",
    "    '--dropout', '0.1',                                       \n",
    "    '--attention_dropout', '0.1',                                      \n",
    "    '--gelu_activation', 'true',\n",
    "    \n",
    "    ## optimization\n",
    "    '--tokens_per_batch', '2000',                                       # use batches with a fixed number of words\n",
    "    '--batch_size', '32',                                               # batch size (for back-translation)\n",
    "    '--bptt', '256',                                                    # sequence length\n",
    "    '--optimizer', 'adam_inverse_sqrt,beta1=0.9,beta2=0.98,lr=0.0001',  # optimizer\n",
    "    '--epoch_size', '200000',                                           # number of sentences per epoch\n",
    "    '--eval_bleu', 'true',                                              # also evaluate the BLEU score\n",
    "    '--stopping_criterion', 'valid_en-fr_mt_bleu,10',                   # validation metric (when to save the best model)\n",
    "    '--validation_metrics', 'valid_en-fr_mt_bleu',\n",
    "])\n",
    "\n",
    "# print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myutils.check_data_params(params)\n",
    "check_model_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU stuff\n",
    "\n",
    "params.n_nodes = 1\n",
    "params.node_id = 0\n",
    "params.local_rank = 0\n",
    "params.global_rank = 0\n",
    "params.world_size = 1\n",
    "params.n_gpu_per_node = 1\n",
    "params.is_master = params.node_id == 0 and params.local_rank == 0\n",
    "params.multi_node = params.n_nodes > 1\n",
    "params.multi_gpu = params.world_size > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mono': {'en': {'train': <src.data.dataset.Dataset at 0x7f781f7f6748>,\n",
       "   'valid': <src.data.dataset.Dataset at 0x7f781f0f4278>,\n",
       "   'test': <src.data.dataset.Dataset at 0x7f781bc112b0>},\n",
       "  'fr': {'train': <src.data.dataset.Dataset at 0x7f781b24c3c8>,\n",
       "   'valid': <src.data.dataset.Dataset at 0x7f781bd0d438>,\n",
       "   'test': <src.data.dataset.Dataset at 0x7f781b34c4a8>}},\n",
       " 'mono_stream': {'en': {'train': <src.data.dataset.StreamDataset at 0x7f781f7f64a8>,\n",
       "   'valid': <src.data.dataset.StreamDataset at 0x7f789c5e0320>,\n",
       "   'test': <src.data.dataset.StreamDataset at 0x7f781bc112e8>},\n",
       "  'fr': {'train': <src.data.dataset.StreamDataset at 0x7f781b24c400>,\n",
       "   'valid': <src.data.dataset.StreamDataset at 0x7f781bd0d470>,\n",
       "   'test': <src.data.dataset.StreamDataset at 0x7f781b34c4e0>}},\n",
       " 'dico': <src.data.dictionary.Dictionary at 0x7f781f7f6470>,\n",
       " 'para': {('en',\n",
       "   'fr'): {'valid': <src.data.dataset.ParallelDataset at 0x7f781b34c5c0>, 'test': <src.data.dataset.ParallelDataset at 0x7f781c012fd0>}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = loader.load_data(params)\n",
    "\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter layer_norm15.0.weight not found.\n",
      "Parameter layer_norm15.0.bias not found.\n",
      "Parameter encoder_attn.0.q_lin.weight not found.\n",
      "Parameter encoder_attn.0.q_lin.bias not found.\n",
      "Parameter encoder_attn.0.k_lin.weight not found.\n",
      "Parameter encoder_attn.0.k_lin.bias not found.\n",
      "Parameter encoder_attn.0.v_lin.weight not found.\n",
      "Parameter encoder_attn.0.v_lin.bias not found.\n",
      "Parameter encoder_attn.0.out_lin.weight not found.\n",
      "Parameter encoder_attn.0.out_lin.bias not found.\n",
      "Parameter layer_norm15.1.weight not found.\n",
      "Parameter layer_norm15.1.bias not found.\n",
      "Parameter encoder_attn.1.q_lin.weight not found.\n",
      "Parameter encoder_attn.1.q_lin.bias not found.\n",
      "Parameter encoder_attn.1.k_lin.weight not found.\n",
      "Parameter encoder_attn.1.k_lin.bias not found.\n",
      "Parameter encoder_attn.1.v_lin.weight not found.\n",
      "Parameter encoder_attn.1.v_lin.bias not found.\n",
      "Parameter encoder_attn.1.out_lin.weight not found.\n",
      "Parameter encoder_attn.1.out_lin.bias not found.\n",
      "Parameter layer_norm15.2.weight not found.\n",
      "Parameter layer_norm15.2.bias not found.\n",
      "Parameter encoder_attn.2.q_lin.weight not found.\n",
      "Parameter encoder_attn.2.q_lin.bias not found.\n",
      "Parameter encoder_attn.2.k_lin.weight not found.\n",
      "Parameter encoder_attn.2.k_lin.bias not found.\n",
      "Parameter encoder_attn.2.v_lin.weight not found.\n",
      "Parameter encoder_attn.2.v_lin.bias not found.\n",
      "Parameter encoder_attn.2.out_lin.weight not found.\n",
      "Parameter encoder_attn.2.out_lin.bias not found.\n",
      "Parameter layer_norm15.3.weight not found.\n",
      "Parameter layer_norm15.3.bias not found.\n",
      "Parameter encoder_attn.3.q_lin.weight not found.\n",
      "Parameter encoder_attn.3.q_lin.bias not found.\n",
      "Parameter encoder_attn.3.k_lin.weight not found.\n",
      "Parameter encoder_attn.3.k_lin.bias not found.\n",
      "Parameter encoder_attn.3.v_lin.weight not found.\n",
      "Parameter encoder_attn.3.v_lin.bias not found.\n",
      "Parameter encoder_attn.3.out_lin.weight not found.\n",
      "Parameter encoder_attn.3.out_lin.bias not found.\n",
      "Parameter layer_norm15.4.weight not found.\n",
      "Parameter layer_norm15.4.bias not found.\n",
      "Parameter encoder_attn.4.q_lin.weight not found.\n",
      "Parameter encoder_attn.4.q_lin.bias not found.\n",
      "Parameter encoder_attn.4.k_lin.weight not found.\n",
      "Parameter encoder_attn.4.k_lin.bias not found.\n",
      "Parameter encoder_attn.4.v_lin.weight not found.\n",
      "Parameter encoder_attn.4.v_lin.bias not found.\n",
      "Parameter encoder_attn.4.out_lin.weight not found.\n",
      "Parameter encoder_attn.4.out_lin.bias not found.\n",
      "Parameter layer_norm15.5.weight not found.\n",
      "Parameter layer_norm15.5.bias not found.\n",
      "Parameter encoder_attn.5.q_lin.weight not found.\n",
      "Parameter encoder_attn.5.q_lin.bias not found.\n",
      "Parameter encoder_attn.5.k_lin.weight not found.\n",
      "Parameter encoder_attn.5.k_lin.bias not found.\n",
      "Parameter encoder_attn.5.v_lin.weight not found.\n",
      "Parameter encoder_attn.5.v_lin.bias not found.\n",
      "Parameter encoder_attn.5.out_lin.weight not found.\n",
      "Parameter encoder_attn.5.out_lin.bias not found.\n"
     ]
    }
   ],
   "source": [
    "encoder, decoder = build_model(params, data_dict['dico'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder, decoder = encoder.cuda(), decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = EncDecTrainer(encoder, decoder, data_dict, params)\n",
    "evaluator = EncDecEvaluator(trainer, data_dict, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = data_dict['para'][('en', 'fr')]['valid'].get_iterator(\n",
    "    shuffle=False, group_by_size=True, n_sentences=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en', 'fr']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9026b94ae4f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mgenerated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang2_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dico'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# decode target sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repository/.personal/XLM/src/model/transformer.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, src_enc, src_len, tgt_lang_id, max_len, sample_temperature)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# input batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0msrc_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;31m# generated sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "lang1_id = params.lang2id[params.langs[0]]\n",
    "lang2_id = params.lang2id[params.langs[1]]\n",
    "\n",
    "for i,batch in tqdm(enumerate(it)):\n",
    "    batch = batch[::-1]\n",
    "    (x1, len1), (x2, len2) = batch\n",
    "    # just create same shape tensor filled with lang_id\n",
    "    langs1 = x1.clone().fill_(lang1_id)\n",
    "    langs2 = x2.clone().fill_(lang2_id)\n",
    "    \n",
    "    alen = torch.arange(len2.max(), dtype=torch.long, device=len2.device)\n",
    "    pred_mask = alen[:, None] < len2[None] - 1\n",
    "    y = x2[1:].masked_select(pred_mask[:-1].bool())\n",
    "    \n",
    "    # encode source sentence\n",
    "    enc1 = encoder('fwd', x=x1, lengths=len1, langs=langs1, causal=False)\n",
    "    enc1 = enc1.transpose(0, 1)\n",
    "    # enc1 = enc1.half() if params.fp16 else enc1\n",
    "\n",
    "    dec2 = decoder('fwd', x=x2, lengths=len2, langs=langs2, causal=True, src_enc=enc1, src_len=len1)\n",
    "    \n",
    "    max_len = int(1.5 * len2.max().item() + 10)\n",
    "    generated, lengths = decoder.generate(dec2, len2, lang2_id, max_len=max_len)\n",
    "    print(convert_to_text(generated, lengths, data_dict['dico'], params))\n",
    "    # decode target sentence\n",
    "    # dec2 = decoder('fwd', x=x2, lengths=len2, langs=langs2, causal=True, src_enc=enc1, src_len=len1)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "scores = evaluator.run_mt(trainer)\n",
    "for k, v in scores.items():\n",
    "    print(\"%s -> %.6f\" % (k, v))\n",
    "    \n",
    "print(\"__log__:%s\" % json.dumps(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
